{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0262bc41-f8dc-4150-8b16-f437a909b75e",
   "metadata": {},
   "source": [
    "# DEMO 3\n",
    "\n",
    "Lasso Regression applied to Stock Market Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe82aee-c62f-44be-b9a1-c92b93578830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Manually set the path relative to the py file's location that you want to import\n",
    "func_lib_path = os.path.abspath(os.path.join(os.getcwd(), '../'))# Add the path to sys.path\n",
    "sys.path.append(func_lib_path)\n",
    "\n",
    "# Now you can import func_lib\n",
    "import func_lib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34aaa4-84a1-4a95-b918-e619148dac1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "historical_prices = func_lib.createHistPrices()\n",
    "list_of_momentums = [1, 5, 15, 20]\n",
    "total_returns     = func_lib.computingReturns(historical_prices, list_of_momentums)\n",
    "total_returns.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98ac81ab-49bf-477a-98a6-f68726701f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the split index for 70% of the dates\n",
    "unique_dates = total_returns.index.get_level_values('Date').unique()\n",
    "split_date = unique_dates[int(0.7 * len(unique_dates))]\n",
    "# Create the training set: all data before the split date\n",
    "train_data = total_returns.loc[total_returns.index.get_level_values('Date') < split_date]\n",
    "\n",
    "# Create the testing set: all data from the split date onwards\n",
    "test_data = total_returns.loc[total_returns.index.get_level_values('Date') >= split_date]\n",
    "\n",
    "features = ['1_d_returns', '5_d_returns', '15_d_returns', '20_d_returns']\n",
    "target   = ['F_1_d_returns']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train = train_data[features]\n",
    "X_test  = test_data[features]\n",
    "y_train = train_data[target]\n",
    "y_test  = test_data[target]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns)\n",
    "X_test_scaled  = pd.DataFrame(X_test_scaled, index=X_test.index, columns=X_test.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
