{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db68f9ed-b3d6-4722-92da-d23681ceaab2",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    "\n",
    "## Reinforcement Learning\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Welcome to this Excercise. We are now going to use our new skills to build our first Deep Learning Reinforcement Learning Model. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab513e37-ff87-42cd-b51e-35de3cbb0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can decide whther we want to download the data or use the saved csv version of it\n",
    "DOWNLOAD_DATA_FROM_API = False \n",
    "MIN_REQUIRED_NUM_OBS_PER_TICKER=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e872ee36-6344-4a65-ba58-f5a7aa80bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "OMP_NUM_THREADS=2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce72d202-638a-48f2-b996-b53ad6d53930",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if DOWNLOAD_DATA_FROM_API == True:\n",
    "    # Get the list of S&P 500 constituents\n",
    "    sp500_tickers = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]['Symbol'].tolist()\n",
    "    \n",
    "    # Filter out Class B shares that have a '.B' in the ticker name\n",
    "    sp500_tickers = [ticker for ticker in sp500_tickers if '.B' not in ticker]\n",
    "    \n",
    "    # Define the start and end dates for historical data\n",
    "    start_date = '2000-01-01'\n",
    "    end_date   = '2024-05-01'\n",
    "    \n",
    "    # Download historical prices for the list of ticker sp500_tickers\n",
    "    historical_prices = yf.download(sp500_tickers, start=start_date, end=end_date)\n",
    "\n",
    "    # Remove the MultiIndex and keep only the second level\n",
    "    historical_prices.columns = historical_prices.columns.droplevel(0)\n",
    "    \n",
    "    # Filter and keep only columns where the first level of the MultiIndex is 'Adj Close'\n",
    "    historical_prices  = historical_prices.loc[:, historical_prices.columns.get_level_values(0) == 'Adj Close']\n",
    "\n",
    "    # Count non-missing values for each ticker\n",
    "    ticker_counts = historical_prices.count()\n",
    "\n",
    "    # Filter out tickers with fewer than n=MIN_REQUIRED_NUM_OBS_PER_TICKER=100 non-missing values\n",
    "    valid_tickers = ticker_counts[ticker_counts >= MIN_REQUIRED_NUM_OBS_PER_TICKER].index\n",
    "    \n",
    "    # Filter the DataFrame based on valid tickers\n",
    "    historical_prices = historical_prices[valid_tickers]\n",
    "    \n",
    "\n",
    "else:\n",
    "    # Read the previously download data\n",
    "    historical_prices = pd.read_csv('historical_prices.csv', index_col='Date', parse_dates=True)\n",
    "    historical_prices.columns.name = 'Ticker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13271b81-60bc-4d34-8baa-b6d7c536a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count non-missing values for each ticker\n",
    "ticker_counts = historical_prices.count()\n",
    "\n",
    "# Filter out tickers with fewer than n=MIN_REQUIRED_NUM_OBS_PER_TICKER=100 non-missing values\n",
    "valid_tickers = ticker_counts[ticker_counts >= MIN_REQUIRED_NUM_OBS_PER_TICKER].index\n",
    "\n",
    "# Filter the DataFrame based on valid tickers\n",
    "historical_prices = historical_prices[valid_tickers]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "951b003f-b564-4ae1-892a-684d3016184c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABNB</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>...</th>\n",
       "      <th>WTW</th>\n",
       "      <th>WY</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>43.613007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.844981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.992848</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.274675</td>\n",
       "      <td>28.438286</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.505342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.977997</td>\n",
       "      <td>18.328693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.680301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.027779</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>40.281452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.773741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.735912</td>\n",
       "      <td>1.270833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.909400</td>\n",
       "      <td>26.999619</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.073115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.138673</td>\n",
       "      <td>17.977634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.586222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.666668</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>37.782795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.719849</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.204174</td>\n",
       "      <td>27.393782</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.659699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.414120</td>\n",
       "      <td>18.957697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.609740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.138889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>36.344185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.024967</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.328290</td>\n",
       "      <td>26.644875</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.205125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.345260</td>\n",
       "      <td>19.937763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.570544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.777779</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>39.372852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.751094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.121321</td>\n",
       "      <td>1.451389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.072987</td>\n",
       "      <td>27.393782</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.803776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.345260</td>\n",
       "      <td>19.879248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.468626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.513889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker              A  AAL      AAPL  ABBV  ABNB       ABT      ACGL  ACN  \\\n",
       "Date                                                                        \n",
       "2000-01-03  43.613007  NaN  0.844981   NaN   NaN  8.992848  1.277778  NaN   \n",
       "2000-01-04  40.281452  NaN  0.773741   NaN   NaN  8.735912  1.270833  NaN   \n",
       "2000-01-05  37.782795  NaN  0.785063   NaN   NaN  8.719849  1.388889  NaN   \n",
       "2000-01-06  36.344185  NaN  0.717125   NaN   NaN  9.024967  1.375000  NaN   \n",
       "2000-01-07  39.372852  NaN  0.751094   NaN   NaN  9.121321  1.451389  NaN   \n",
       "\n",
       "Ticker           ADBE        ADI  ...  WTW         WY  WYNN       XEL  \\\n",
       "Date                              ...                                   \n",
       "2000-01-03  16.274675  28.438286  ...  NaN  11.505342   NaN  6.977997   \n",
       "2000-01-04  14.909400  26.999619  ...  NaN  11.073115   NaN  7.138673   \n",
       "2000-01-05  15.204174  27.393782  ...  NaN  11.659699   NaN  7.414120   \n",
       "2000-01-06  15.328290  26.644875  ...  NaN  12.205125   NaN  7.345260   \n",
       "2000-01-07  16.072987  27.393782  ...  NaN  11.803776   NaN  7.345260   \n",
       "\n",
       "Ticker            XOM  XYL       YUM  ZBH       ZBRA  ZTS  \n",
       "Date                                                       \n",
       "2000-01-03  18.328693  NaN  4.680301  NaN  25.027779  NaN  \n",
       "2000-01-04  17.977634  NaN  4.586222  NaN  24.666668  NaN  \n",
       "2000-01-05  18.957697  NaN  4.609740  NaN  25.138889  NaN  \n",
       "2000-01-06  19.937763  NaN  4.570544  NaN  23.777779  NaN  \n",
       "2000-01-07  19.879248  NaN  4.468626  NaN  23.513889  NaN  \n",
       "\n",
       "[5 rows x 499 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 5 rows\n",
    "historical_prices.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78fdd493-bd65-4445-9276-95b20d73e219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticker\n",
       "A       6120\n",
       "AAL     4679\n",
       "AAPL    6120\n",
       "ABBV    2851\n",
       "ABNB     851\n",
       "        ... \n",
       "XYL     3156\n",
       "YUM     6120\n",
       "ZBH     5727\n",
       "ZBRA    6120\n",
       "ZTS     2830\n",
       "Length: 499, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_prices.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4f77062-2b2f-4209-9cc1-e5a79ae9da3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6120 entries, 2000-01-03 to 2024-04-30\n",
      "Columns: 499 entries, A to ZTS\n",
      "dtypes: float64(499)\n",
      "memory usage: 23.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Use the pandas info function to verify the data types of the dataframe column\n",
    "historical_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "183a3ebe-fff8-4b10-a0ee-16c5bdb63e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computingReturns(close_prices,list_of_momentums): \n",
    "    forecast=1        \n",
    "    f_returns = close_prices.pct_change(forecast)            \n",
    "    f_returns = f_returns.shift(-forecast)\n",
    "    f_returns = pd.DataFrame(f_returns.unstack())\n",
    "    name = \"F_\"+str(forecast)+\"_d_returns\"\n",
    "    f_returns.rename(columns={0: name}, inplace = True)\n",
    "    f_returns.reset_index(inplace = True)\n",
    "    f_returns.rename(columns={'level_0':'Ticker'}, inplace=True)\n",
    "    # We add the forward returns to total_returns\n",
    "    total_returns = f_returns\n",
    "    \n",
    "    for i in list_of_momentums:   \n",
    "        feature = close_prices.pct_change(i)\n",
    "        feature = pd.DataFrame(feature.unstack())\n",
    "        name = str(i)+\"_d_returns\"        \n",
    "        feature.reset_index(inplace = True)\n",
    "        feature.rename(columns={0: name, 'level_0':'Ticker'}, inplace = True)\n",
    "        # We add each \n",
    "        total_returns = pd.merge(total_returns,feature,left_on=['Ticker', 'Date'],right_on=['Ticker', 'Date'], how='left', suffixes=('_original', 'right'))\n",
    "      \n",
    "    total_returns.dropna(axis=0, how='any', inplace=True) \n",
    "    total_returns.set_index(['Date', 'Ticker'], inplace=True)\n",
    "\n",
    "    return total_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d73be1a7-848d-4f1f-baaf-bf921760544b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>F_1_d_returns</th>\n",
       "      <th>1_d_returns</th>\n",
       "      <th>2_d_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <th>A</th>\n",
       "      <td>-0.038076</td>\n",
       "      <td>-0.062030</td>\n",
       "      <td>-0.133681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <th>A</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.038076</td>\n",
       "      <td>-0.097744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <th>A</th>\n",
       "      <td>0.060577</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.042084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <th>A</th>\n",
       "      <td>-0.013599</td>\n",
       "      <td>0.060577</td>\n",
       "      <td>0.148958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-11</th>\n",
       "      <th>A</th>\n",
       "      <td>-0.020221</td>\n",
       "      <td>-0.013599</td>\n",
       "      <td>0.046154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   F_1_d_returns  1_d_returns  2_d_returns\n",
       "Date       Ticker                                         \n",
       "2000-01-05 A           -0.038076    -0.062030    -0.133681\n",
       "2000-01-06 A            0.083333    -0.038076    -0.097744\n",
       "2000-01-07 A            0.060577     0.083333     0.042084\n",
       "2000-01-10 A           -0.013599     0.060577     0.148958\n",
       "2000-01-11 A           -0.020221    -0.013599     0.046154"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can choose how many momentums and which ones we want to create\n",
    "list_of_momentums = [1,2] # [1,2,3,4,5,10].\n",
    "#list_of_momentums = []\n",
    "total_data = computingReturns(historical_prices, list_of_momentums)\n",
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf28c9b3-3944-48c4-b42b-16903c4590cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1308720-0eb4-44dc-8091-06d3b53143eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import random\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcfec5c-0944-470e-a81e-f12aae7668ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self, df):\n",
    "        super(CustomEnv, self).__init__()\n",
    "        self.df = df\n",
    "        self.action_space = gym.spaces.Discrete(1)  # Action space (predict F_1_d_returns)\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(2,), dtype=np.float32)  # State space (1_d_returns, 2_d_returns)\n",
    "        self.current_step = 0\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the environment to initial state\n",
    "        self.current_step = 0\n",
    "        self.state = self.df.iloc[self.current_step, 1:3].values  # Start with first row's 1_d_returns and 2_d_returns\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Take an action (not relevant here as we are predicting)\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.df) - 1\n",
    "        if done:\n",
    "            next_state = self.state\n",
    "        else:\n",
    "            next_state = self.df.iloc[self.current_step, 1:3].values\n",
    "        reward = 0  # No reward for predicting\n",
    "        info = {}   # Additional information (if needed)\n",
    "        return next_state, reward, done, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcc8797-12b9-4b7d-b022-1fa60d69d82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomEnv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80a4d3-91a2-4eb4-8be3-953bc57218f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "#from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1780ed-c99f-4f9a-b8b3-dbcadc2a2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98475236-e671-4db2-99f9-995e0edd0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047b240-e06f-41d0-84de-0202f11bf7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom model\n",
    "def build_model(input_shape, nb_actions):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))  # Adjust input shape here\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(nb_actions, activation='linear'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004ad10-13f0-4953-8220-24d54f0d2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20d8d7-458c-4d59-8041-3a783f12017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b60f436-be34-448e-913c-50de93a60095",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e1261-1d6d-4c4d-bce9-38519dcc1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import __version__\n",
    "tf.keras.__version__ = __version__\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37572412-02b0-4b7b-a3d1-b174c7c3dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84c88a-887e-42bf-893b-148d62a011a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c9446c-b865-4964-a784-5e52378afdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97ffc392-08db-463c-a2a3-a534d92c362e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Creating a OutOfGraphReplayBuffer replay memory with the following parameters:\n",
      "INFO:absl:\t observation_shape: (1, 2)\n",
      "INFO:absl:\t observation_dtype: <class 'numpy.uint8'>\n",
      "INFO:absl:\t terminal_dtype: <class 'numpy.uint8'>\n",
      "INFO:absl:\t stack_size: 1\n",
      "INFO:absl:\t replay_capacity: 100000\n",
      "INFO:absl:\t batch_size: 32\n",
      "INFO:absl:\t update_horizon: 1\n",
      "INFO:absl:\t gamma: 0.990000\n",
      "INFO:absl:\t checkpoint_duration: 4\n",
      "INFO:absl:\t keep_every: None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot sample a batch with fewer than stack size (1) + update_horizon (1) transitions.\n  In call to configurable 'WrappedReplayBuffer' (<class 'dopamine.replay_memory.circular_replay_buffer.WrappedReplayBuffer'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 61\u001b[0m\n\u001b[0;32m     55\u001b[0m sess \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Set up a replay buffer\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Set up a replay buffer with increased capacity\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m replay_buffer \u001b[38;5;241m=\u001b[39m circular_replay_buffer\u001b[38;5;241m.\u001b[39mWrappedReplayBuffer(\n\u001b[0;32m     62\u001b[0m     observation_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m+\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m     63\u001b[0m     stack_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     64\u001b[0m     replay_capacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m)  \u001b[38;5;66;03m# Increased capacity\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Create the agent\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Create the agent with decreased min replay history\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Create the agent with a higher min replay history\u001b[39;00m\n\u001b[0;32m     70\u001b[0m agent \u001b[38;5;241m=\u001b[39m dqn_agent\u001b[38;5;241m.\u001b[39mDQNAgent(\n\u001b[0;32m     71\u001b[0m     sess,\n\u001b[0;32m     72\u001b[0m     num_actions\u001b[38;5;241m=\u001b[39menv\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m     target_update_period\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     82\u001b[0m     epsilon_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gin\\config.py:1605\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m scope_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in scope \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(scope_str) \u001b[38;5;28;01mif\u001b[39;00m scope_str \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1604\u001b[0m err_str \u001b[38;5;241m=\u001b[39m err_str\u001b[38;5;241m.\u001b[39mformat(name, fn_or_cls, scope_info)\n\u001b[1;32m-> 1605\u001b[0m utils\u001b[38;5;241m.\u001b[39maugment_exception_message_and_reraise(e, err_str)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gin\\utils.py:41\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[1;34m(exception, message)\u001b[0m\n\u001b[0;32m     39\u001b[0m proxy \u001b[38;5;241m=\u001b[39m ExceptionProxy()\n\u001b[0;32m     40\u001b[0m ExceptionProxy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(exception)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m proxy\u001b[38;5;241m.\u001b[39mwith_traceback(exception\u001b[38;5;241m.\u001b[39m__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gin\\config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1579\u001b[0m new_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1582\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m   1584\u001b[0m   err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dopamine\\replay_memory\\circular_replay_buffer.py:918\u001b[0m, in \u001b[0;36mWrappedReplayBuffer.__init__\u001b[1;34m(self, observation_shape, stack_size, use_staging, replay_capacity, batch_size, update_horizon, gamma, wrapped_memory, max_sample_attempts, extra_storage_types, observation_dtype, terminal_dtype, action_shape, action_dtype, reward_shape, reward_dtype)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    901\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory \u001b[38;5;241m=\u001b[39m OutOfGraphReplayBuffer(\n\u001b[0;32m    902\u001b[0m       observation_shape,\n\u001b[0;32m    903\u001b[0m       stack_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    915\u001b[0m       reward_dtype\u001b[38;5;241m=\u001b[39mreward_dtype,\n\u001b[0;32m    916\u001b[0m   )\n\u001b[1;32m--> 918\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_sampling_ops(use_staging)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dopamine\\replay_memory\\circular_replay_buffer.py:953\u001b[0m, in \u001b[0;36mWrappedReplayBuffer.create_sampling_ops\u001b[1;34m(self, use_staging)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/cpu:*\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    952\u001b[0m   transition_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mget_transition_elements()\n\u001b[1;32m--> 953\u001b[0m   transition_tensors \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnumpy_function(\n\u001b[0;32m    954\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39msample_transition_batch,\n\u001b[0;32m    955\u001b[0m       [],\n\u001b[0;32m    956\u001b[0m       [return_entry\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m return_entry \u001b[38;5;129;01min\u001b[39;00m transition_type],\n\u001b[0;32m    957\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplay_sample_py_func\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    958\u001b[0m   )\n\u001b[0;32m    959\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_transition_shape(transition_tensors, transition_type)\n\u001b[0;32m    960\u001b[0m   \u001b[38;5;66;03m# Unpack sample transition into member variables.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dopamine\\replay_memory\\circular_replay_buffer.py:599\u001b[0m, in \u001b[0;36mOutOfGraphReplayBuffer.sample_transition_batch\u001b[1;34m(self, batch_size, indices)\u001b[0m\n\u001b[0;32m    597\u001b[0m   batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 599\u001b[0m   indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_index_batch(batch_size)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indices) \u001b[38;5;241m==\u001b[39m batch_size\n\u001b[0;32m    602\u001b[0m transition_elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transition_elements(batch_size)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dopamine\\replay_memory\\circular_replay_buffer.py:540\u001b[0m, in \u001b[0;36mOutOfGraphReplayBuffer.sample_index_batch\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m    538\u001b[0m   max_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_horizon\n\u001b[0;32m    539\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m max_id \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m min_id:\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot sample a batch with fewer than stack size \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    542\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) + update_horizon (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) transitions.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    543\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stack_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_horizon\n\u001b[0;32m    544\u001b[0m         )\n\u001b[0;32m    545\u001b[0m     )\n\u001b[0;32m    547\u001b[0m indices \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    548\u001b[0m attempt_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot sample a batch with fewer than stack size (1) + update_horizon (1) transitions.\n  In call to configurable 'WrappedReplayBuffer' (<class 'dopamine.replay_memory.circular_replay_buffer.WrappedReplayBuffer'>)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "import dopamine\n",
    "import logging  # Add this line\n",
    "from dopamine.agents.dqn import dqn_agent\n",
    "from dopamine.replay_memory import circular_replay_buffer\n",
    "from dopamine.colab import utils as colab_utils\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Create your environment\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self, df):\n",
    "        super(CustomEnv, self).__init__()\n",
    "        self.df = df\n",
    "        self.action_space = gym.spaces.Discrete(1)  # Action space (predict F_1_d_returns)\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(2,), dtype=np.float32)  # State space (1_d_returns, 2_d_returns)\n",
    "        self.current_step = 0\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the environment to initial state\n",
    "        self.current_step = 0\n",
    "        self.state = self.df.iloc[self.current_step, 1:3].values  # Start with first row's 1_d_returns and 2_d_returns\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Take an action (not relevant here as we are predicting)\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.df) - 1\n",
    "        if done:\n",
    "            next_state = self.state\n",
    "        else:\n",
    "            next_state = self.df.iloc[self.current_step, 1:3].values\n",
    "        reward = 0  # No reward for predicting\n",
    "        info = {}   # Additional information (if needed)\n",
    "        return next_state, reward, done, info\n",
    "\n",
    "# Create your environment\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'F_1_d_returns': [-0.038076, 0.083333, 0.060577, -0.013599, -0.020221],\n",
    "    '1_d_returns': [-0.062030, -0.038076, 0.083333, 0.060577, -0.013599],\n",
    "    '2_d_returns': [-0.133681, -0.097744, 0.042084, 0.148958, 0.046154]\n",
    "})\n",
    "\n",
    "env = CustomEnv(df)\n",
    "\n",
    "# Set up logging\n",
    "LOG_PATH = '/tmp/dopamine/logs'\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Create a TensorFlow session\n",
    "tf.compat.v1.reset_default_graph()\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "# Set up a replay buffer\n",
    "\n",
    "\n",
    "# Set up a replay buffer with increased capacity\n",
    "replay_buffer = circular_replay_buffer.WrappedReplayBuffer(\n",
    "    observation_shape=(1,) + env.observation_space.shape,\n",
    "    stack_size=1,\n",
    "    replay_capacity=100000)  # Increased capacity\n",
    "\n",
    "\n",
    "# Create the agent\n",
    "# Create the agent with decreased min replay history\n",
    "# Create the agent with a higher min replay history\n",
    "agent = dqn_agent.DQNAgent(\n",
    "    sess,\n",
    "    num_actions=env.action_space.n,\n",
    "    observation_shape=(1,) + env.observation_space.shape,\n",
    "    observation_dtype=tf.float32,\n",
    "    stack_size=1,\n",
    "    network='dqn',\n",
    "    gamma=0.99,\n",
    "    update_horizon=1,\n",
    "    min_replay_history=1000,  # Increase min replay history\n",
    "    update_period=4,\n",
    "    target_update_period=100,\n",
    "    epsilon_fn=lambda x: 0.1)\n",
    "\n",
    "# Create a checkpoint directory\n",
    "checkpoint_dir = os.path.join(LOG_PATH, 'checkpoints')\n",
    "checkpoint_file_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Create a logger\n",
    "logger = colab_utils.Logger(LOG_PATH)\n",
    "\n",
    "# Initialize variables\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "# Train the agent\n",
    "for episode in range(100):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.begin_episode(obs)\n",
    "        next_obs, reward, done, _ = env.step(action)\n",
    "        agent.end_episode(reward)\n",
    "        replay_buffer.add(obs, action, reward, next_obs, done)\n",
    "        obs = next_obs\n",
    "\n",
    "        if len(replay_buffer) >= agent.min_replay_history:\n",
    "            experience = replay_buffer.sample(1)\n",
    "            agent.step(experience)\n",
    "\n",
    "    if episode % 10 == 0:\n",
    "        logger.scalar_summary('Return', reward, step=episode)\n",
    "\n",
    "# Save the final checkpoint\n",
    "checkpoint_path = agent._saver.save(sess, checkpoint_file_prefix)\n",
    "print('Final checkpoint saved at: %s' % checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d84ea-6f0c-4925-aa93-519b37e13aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a262fe-3a92-41cb-affe-80c3cc766a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dqn.test(env, nb_episodes=100, visualize=False)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef5049-72f6-418e-b9fa-0ab1686772c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model\n",
    "input_shape = env.observation_space.shape[0]\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25263302-6ce2-40ea-b86a-cb16d70ecf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = build_model(input_shape, nb_actions)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486f0c5-a91a-42a4-b5d5-7416eefc0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the memory\n",
    "memory = SequentialMemory(limit=10000, window_length=1)\n",
    "\n",
    "# Define the policy\n",
    "policy = BoltzmannQPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f445d7-e2c1-4bd8-a852-4adca71be1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DQN agent\n",
    "dqn = DQNAgent(model=model, memory=memory, policy=policy, nb_actions=nb_actions,\n",
    "               nb_steps_warmup=100, target_model_update=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b5c1c-bbf3-4278-bcd0-e442d3626b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# Instantiate the optimizer\n",
    "optimizer = Adam(learning_rate=0.001)  # Adjust learning rate as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daae944-1024-4675-8c5e-9fe1f9885b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer._name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442aeed-00c0-4a73-bfc6-6c1924d7b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "dqn.compile(optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d934662-33de-446b-9b36-db5a6bbcfea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "dqn.compile(optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1b10d-b112-480e-8147-52b7e081f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Train the agent\n",
    "dqn.fit(env, nb_steps=5000, visualize=False, verbose=1)\n",
    "\n",
    "# Predict using the trained agent\n",
    "obs = env.reset()  # Reset the environment\n",
    "for _ in range(len(df) - 1):\n",
    "    action = dqn.forward(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    # Here, obs contains the predicted F_1_d_returns for each step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14e20259-cc35-47e9-8af9-a472e46cb01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\\\Users\\\\cramk\\\\Documents\\\\Metin\\\\building-a-workflow-for-aI\\\\l5-reinforcement-learning\\\\–V': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python –V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87c55e8e-757c-43e7-96c2-357652d10c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03286f4e-89e8-4615-9ac2-52a0ded7874e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
